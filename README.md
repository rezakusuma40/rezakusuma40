Hi there, I'm REZA 👋
---
🚀 Junior Data Engineer | Aspiring Data Scientist | AI Enthusiast
🎓 Currently working as a junior data engineer and enrolled in a Data Science Bootcamp
🔧 Passionate about data analytics, data engineering, and exploring the world of artificial intelligence!

🌟 About Me
💻 My journey began with a Data Engineering Bootcamp, followed by hands-on professional experience, and now I’m diving deeper into Data Science and AI through my bootcamp.
📈 I’m building end-to-end solutions and continually sharpening my skills to create insightful, actionable data products.

🔧 Tools & Technologies
👷‍♂️ Data Engineering Skills:
Languages: Python, SQL (PostgreSQL)
Tools/Platforms: DBeaver, PySpark, SparkSQL, Spark Streaming, Airflow, Kafka, Elasticsearch, Kibana, Docker, GitHub
Cloud Tech: Google Cloud Platform (GCP) – Cloud Storage, Compute Engine, BigQuery, Dataproc, Looker
Processes: ETL, Data Pipelines, Data Preprocessing, ERD & Data Warehouse Modeling, Web Scraping (BeautifulSoup, Selenium)
💼 In My Current Job:
Focus Areas: Web Scraping (BeautifulSoup, Selenium), Data Cleaning, BigQuery, Cloud Storage, SQL, GitHub
📚 What I Have Learned at My Data Science Bootcamp:
Core Skills: Python, Jupyter & Colab Notebooks, Data Preprocessing, EDA, Visualization, Data Transformation, Feature Engineering
Libraries/Tools: Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, Tableau, Power BI
Techniques: Hypothesis Testing, Basic ML Algorithms
🔮 And Next:
Advanced Topics: End-to-End Data Science Projects, Advanced ML Algorithms (e.g., Random Forest, XGBoost), Hyperparameter Tuning, Imbalance Handling, Model Evaluasion, etc..


## 📂 **Featured Projects**
1. End-to-End Data Pipeline for Investment Tweets 📊
A comprehensive pipeline built in GCP, combining batch and stream processing:

Scraped investment-related tweets using Twitter API & Kafka (streaming).
Loaded raw data to a data lake, transformed it via Dataproc (PySpark), and stored in BigQuery & Elasticsearch.
Created dashboards in Looker Studio for insightful visualizations.

2. Private Lease Cars Scraping 🚗
Web scraping a dynamic site using Selenium and Selenium Wire:

Leveraged retry mechanisms and API scraping for optimal performance.
Compared methods for reliability and speed, with periodic scraping capability.

3. Telco Churn Exploratory Data Analysis 📈
An Exploratory Data Analysis (EDA) project using Telco Churn Dataset:

Conducted univariate & bivariate analysis with impactful visualizations.
Used techniques for data preparation and deep-dive analysis.

4. Telco Churn Predictive Modeling 🤖
An end-to-end machine learning project:

Steps Involved: Data Preparation, EDA, Encoding, Train-Val-Test Split, Imbalance Handling
Will use 2 ML algorithms with cross-validation and evaluation metrics.
🌈 Let’s Connect!
📫 Reach me at [muhammadkusumareza@gmail.com](muhammadkusumareza@gmail.com)
💼 Connect on [my LinkedIn](https://www.linkedin.com/in/muhammadrezaadikusuma/)


"Turning data into insights, and insights into impact."
